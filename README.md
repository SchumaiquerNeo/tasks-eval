# ğŸ“Š Benchmark Runner (MMLU & GSM8K)

Este projeto permite rodar benchmarks **MMLU** e **GSM8K** em modelos da OpenAI (ex.: `gpt-4o`, `gpt-4o-mini`, `gpt-4`) de forma simples e configurÃ¡vel.  
Ele integra:
- ConfiguraÃ§Ã£o via **YAML** (`config.yaml`)
- **.env** para manter sua chave de API segura
- **Makefile** para automatizar instalaÃ§Ã£o e execuÃ§Ã£o
- Suporte a concorrÃªncia assÃ­ncrona (para acelerar execuÃ§Ã£o no MMLU)

---

## ğŸš€ Setup

### 1. Clone e crie ambiente virtual
```bash
git clone <repo>
cd mmlu-run
python3 -m venv .venv
source .venv/bin/activate
```

### 2. Instale dependÃªncias

```bash
pip install -r requirements.txt
```

### ğŸ”‘ ConfiguraÃ§Ã£o da API

Crie um arquivo .env na raiz do projeto:

```ini
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
```

## âš™ï¸ ConfiguraÃ§Ã£o de benchmark

Ajuste config.yaml:

```yaml
models:
  - gpt-4o
  - gpt-4o-mini

# Escolha o benchmark: "mmlu" ou "gsm8k"
task: gsm8k

# ConfiguraÃ§Ãµes gerais
n_fewshot: 5
max_samples: 200   # use None para dataset completo
num_concurrent: 5
output_dir: results

```

## â–¶ï¸ ExecuÃ§Ã£o

O Makefile jÃ¡ cuida de tudo:

```bash
make run
```
- Se task: mmlu â†’ roda o script assÃ­ncrono run_mmlu_all_async.py
- Se task: gsm8k â†’ roda lm_eval diretamente, um JSON por modelo

## ğŸ“‚ Resultados

### GSM8K

Saem na pasta results/, um JSON por modelo:

```bash
results/gsm8k_gpt-4o.json
results/gsm8k_gpt-4o-mini.json
```

### MMLU

- Resultados detalhados por categoria:

```bash
results/mmlu_full_results_async.json
```

- Resumo geral por modelo (CSV):

```bash
results/mmlu_summary_async.csv
```